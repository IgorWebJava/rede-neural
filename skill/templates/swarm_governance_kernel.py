import numpy as np
from numba import jit, prange

# ----------------------------------------------------------------------
# 1. Swarm Trust-Weighting Kernel
# ----------------------------------------------------------------------

@jit(nopython=True, parallel=True)
def calculate_trust_scores(stability_history, performance_metrics, uptime_data):
    """
    Calcula o score de confian√ßa de cada agente no enxame.
    - stability_history: Hist√≥rico de auto-corre√ß√µes (0.0 a 1.0)
    - performance_metrics: Precis√£o em tarefas de valida√ß√£o (0.0 a 1.0)
    - uptime_data: Maturidade operacional (normalizado)
    """
    num_agents = stability_history.shape[0]
    trust_scores = np.zeros(num_agents)
    
    for i in prange(num_agents):
        # Pondera√ß√£o: 40% Estabilidade, 40% Performance, 20% Uptime
        score = (stability_history[i] * 0.4) + \
                (performance_metrics[i] * 0.4) + \
                (uptime_data[i] * 0.2)
        trust_scores[i] = score
        
    # Normaliza√ß√£o Softmax para pesos de fus√£o
    max_score = np.max(trust_scores)
    exp_scores = np.exp(trust_scores - max_score)
    return exp_scores / np.sum(exp_scores)

@jit(nopython=True, parallel=True)
def sovereign_policy_fusion(policies, trust_weights):
    """
    Realiza a fus√£o ponderada de pol√≠ticas (Q-Tables) de m√∫ltiplos agentes.
    - policies: Tensor (Agentes, Estados, A√ß√µes)
    - trust_weights: Vetor de pesos de confian√ßa por agente
    """
    num_agents, num_states, num_actions = policies.shape
    global_policy = np.zeros((num_states, num_actions))
    
    for i in range(num_agents):
        weight = trust_weights[i]
        for s in prange(num_states):
            for a in range(num_actions):
                global_policy[s, a] += policies[i, s, a] * weight
                
    return global_policy

# ----------------------------------------------------------------------
# 2. Monitor de Governan√ßa (RULE 11)
# ----------------------------------------------------------------------

class SwarmGovernance:
    """
    Gerenciador de Governan√ßa do Enxame Soberano.
    Garante que apenas agentes confi√°veis influenciem o modelo global.
    """
    def __init__(self, threshold=0.1):
        self.threshold = threshold # Peso m√≠nimo para participar da fus√£o

    def audit_swarm(self, agents_data):
        """
        Audita o enxame e gera pesos de fus√£o.
        """
        # Simula√ß√£o de extra√ß√£o de m√©tricas (em prod viria do persistence/logs)
        stability = np.array([d['stability'] for d in agents_data])
        performance = np.array([d['performance'] for d in agents_data])
        uptime = np.array([d['uptime'] for d in agents_data])
        
        weights = calculate_trust_scores(stability, performance, uptime)
        
        # RULE 05: Hardening de Estado - Filtrar agentes abaixo do threshold
        weights[weights < self.threshold] = 0.0
        # Re-normalizar
        if np.sum(weights) > 0:
            weights = weights / np.sum(weights)
            
        return weights

if __name__ == '__main__':
    # Exemplo de Governan√ßa em Enxame de 3 Agentes
    agents = [
        {'name': 'Agent_A', 'stability': 0.95, 'performance': 0.92, 'uptime': 1.0},
        {'name': 'Agent_B', 'stability': 0.40, 'performance': 0.50, 'uptime': 0.2}, # Inst√°vel
        {'name': 'Agent_C', 'stability': 0.88, 'performance': 0.85, 'uptime': 0.8}
    ]
    
    gov = SwarmGovernance(threshold=0.15)
    weights = gov.audit_swarm(agents)
    
    print("üìä Pesos de Confian√ßa do Enxame:")
    for i, a in enumerate(agents):
        print(f"  - {a['name']}: {weights[i]:.4f}")
    
    if weights[1] == 0:
        print("\nüõ°Ô∏è RULE 05: Agent_B foi isolado por baixa estabilidade.")
