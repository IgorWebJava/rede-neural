import numpy as np

class SovereignExplainer:
    """
    Camada de Explicabilidade Soberana (RULE 14).
    V10: Traduz ativa√ß√µes neurais e decis√µes do enxame em relat√≥rios leg√≠veis.
    """
    def __init__(self, model_params):
        self.params = model_params

    def explain_prediction(self, vision_feat, text_feat, prediction):
        """
        Analisa a contribui√ß√£o de cada modalidade para a predi√ß√£o final.
        """
        # C√°lculo simplificado de contribui√ß√£o (Magnitude de Ativa√ß√£o)
        v_magnitude = np.mean(np.abs(vision_feat))
        t_magnitude = np.mean(np.abs(text_feat))
        
        total = v_magnitude + t_magnitude + 1e-8
        v_contrib = (v_magnitude / total) * 100
        t_contrib = (t_magnitude / total) * 100
        
        explanation = {
            "prediction": "POSITIVA" if prediction > 0.5 else "NEGATIVA",
            "confidence": f"{abs(prediction - 0.5) * 200:.2f}%",
            "modalities": {
                "vision": f"{v_contrib:.2f}% de influ√™ncia",
                "text": f"{t_contrib:.2f}% de influ√™ncia"
            },
            "reasoning": self._generate_reasoning(v_contrib, t_contrib)
        }
        return explanation

    def _generate_reasoning(self, v_contrib, t_contrib):
        if v_contrib > t_contrib:
            return "A decis√£o foi baseada predominantemente em padr√µes visuais detectados."
        else:
            return "A decis√£o foi baseada predominantemente no contexto textual analisado."

    def log_explanation(self, explanation):
        print("\n--- üß† EXPLICA√á√ÉO SOBERANA ---")
        print(f"Resultado: {explanation['prediction']} (Confian√ßa: {explanation['confidence']})")
        print(f"Influ√™ncia Vis√£o: {explanation['modalities']['vision']}")
        print(f"Influ√™ncia Texto: {explanation['modalities']['text']}")
        print(f"Racioc√≠nio: {explanation['reasoning']}")
        print("------------------------------")
